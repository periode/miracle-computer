Hello,

A miracle is the moment where the mass, witnessing the unexpected, does not understand what happened, and listens to the one who, retaining enough composure, says “I told you so”. The proof, usually, is written text. The strength, the certainty of text cannot be questioned through the fleeting quality of human speech. As carved, printed and drawn words expanded to form to encompass human life, in both its practices and its ideals, it is the most abstract of their sub-groups, numbers, which gave birth to the last miracle.

The turing paper, the original scripture for that manifestation, only bothered itself with ideals. Its applied mathematics, as it turned out to be, were quite un-rigorous. But the word is there for the mind, and not for the deed. What is a theoretical solution to a theoretical problem, and the description of vague -by the mathematician's standards- guideline to implement this theory seems to be but an afterthought. The unseen phenomenon here isn't the simple implementation of theories, but the implementation of an all-encompassing theory. If you had such a device, and the need for that devices stems only from the our biological limitations, then you could know all. The Entscheidungsproblem is the decision problem. Can we make a decision, an un-arbitrary, un-ambivalent, a binary decision? The fluidity, the ever-evolving, consuming and forgetful quality of our minds seems to prevent us from doing so. The Turing paper, then is but the newest iteration in our long list of claims for universality. It was first about the world of numbers.

The purpose, then wasn't to have a physical proof of universal decision making, the purpose was to provide mental re-assurance., to KNOW that it was possible to KNOW. That even if we weren't able to hold and manifest that knowledge, we could rely on the fact that there was a system that could. Systems we've always relied on, and even more once they manifested their omnipotence through physical manifestations.

It started just like any other miracle. Recognized only within a community which was already persuaded. All knew the writer at the time, and acknowledged his unusual capacities, and so they took their word for granted, and so they started building a computing machine. The machine was according to the word, it would store, process, store, process, store, process, until a given state was reached, and then it would wait, ready to store and process again.


#### THE APPLICATION

> mention that the mental certainty was present in the community
> the fact that it is explainable doesn't prevent it from being worshipped
> worshipping the explainable is exactly the point of the ones who (with)hold the power.
> a supplement to human memory
> a carelessness, a coldness that was needed in science
> but also the power trip of being able to manipulate that miracle, the desire to go further and apply principles which maybe weren't there to begin with

The mental certainty of the universal truth stemming from Turing's paper was confirmed by the physical implementation of the scripture. The computer was prophetized by writings, and was foreshadowed by the work of Babbage and Lovelace on their Analytical and Differential Engines. As a manifestation, then it was not un-explained, it was only the consecration of thought into matter, of rational thought (science) into rational matter (a machine). That explainability, that rationality of the computer did not prevent it from being worshipped; on the contrary, it is the level at which it remained true to the essence of theoretical sciences' practice that carved its place inside the scientific community.
In parallel, the explosion of system of values in the western world left a gaping wound which had to be healed by an alternative -if possible, an alternative far from the biological, moral and subjective failures of human minds. The computing machine did not rely on any of those. It came from the world of ideas, and allowed humans to access it, to query, in search of universal answers and decisions -so far applied to sciences. The cold, explainable nature of gear, tape and reading heads stood in stark and necessary contrast to the heated matter of a global conflict. Point in case, the apex of that heat, the atom bomb, was tolerated as a proof of science's power, of god's wrath.
And still, the perfect logic behind both the bomb and the computer, beheld by the greater public, still remained in the heads of a few clergymen, scattered between universities in the United States. To know how to work the machine is to have at one's hands the ability to solve the decision problem, to find an answer and a truth as the output of successive steps of read, process, write.
Science, as all religions, sees itself as a vehicle for the betterment of mankind, and that which is not represented through graspable form cannot prosper. From tape and head, then, we moved to magnetism and vacuum tubes, and as the hardware became easier and more efficient, we tried to make notation easier and more efficient. Causing the wrath of some of their elders, some graduate students started working towards a way to move away from the undesirable side-effects of a machine -that is, its inability to understand us. If we were to solve our problems, if we were to ask the machine for the decisions to make, we had to renegotiate the terms of understanding. While retaining its physical certainty -and, through miniaturization, optimizing that certainty-, we started working on abstraction.
It was decided that the variations in voltage current would be represented by two numbers, 0 and 1, a binary digit, a bit. It wasn't too much of a conceptual leap to represent numbers as other numbers, combining them into supersets of bits, which were standardized as bytes. The basic mathematical operations needed for the machine to reach a decision, however, could not be represented as a single number. While existing in purely logical terms, they had to be referred to in human terms. It is through language that the universal machine truly stepped into our world. Some people agreed that ADD would be represented as numbers, that a word, an idea, a relation, would be boiled down -and some would say reduced- to a set of numbers. In that case, ADD became 011010000110111101110111001000000110010001101111001000000111100101101111011101010010000001110010011001010111000001110010011001010111001101100101011011100111010000100000010000010100010001000100.


#### THE OOP

With that switch came a new beginning, and as with all beginnings was a new word. The apparition of new words, new ways to communicate to that machine, announced the dawn of a renewed computing miracle. Beyond the reaches of a strictly mathematical depiction of the word, we thrived towards a representation system which could, beyond simple semantics gymnastics, loop back on its represented system and modify it.
The main shift behind that commitment was the shift between procedural programming and imperative programming -and more precisely what is referred to as object-oriented programming.
Mathematical expressions became statements, statements implied states, enabled -or restrained, depending who you ask- by the desire to retain a somewhat shadow of the mechanical architecture behind the whole process. ADD could still be traced back to its binary digit equivalent. A short-hand, but with long-reaching consequences, happened with the implementation of Boolean logic into the inner workings of our computings. The equality, or the inequality of a given mathematical expression, of an ideological wording, became recognized as being TRUE or FALSE, and the binary encoding of our system took a life of its own, standing on the shoulders of manichaenism.
Object-Oriented programming, on the other hand, allowed us to write instructions which related to our world, to our consciousness of the world. It allowed us to recombine the building blocks of the Turing paper. It allows to create, describe and act upon clusters of data. Naming that data, which came from an endeavor to relieve programmers from the mental somersaults of describing what was appearing around us, resulted in a manipulable, processable representation of our world. From making decisions with numbers, we ended up making decisions with our physical, non-discreet environment.
This how we made the machine, if not understand, at least act upon the mental representation of the world that computer programmers lived in. Turning language into numbers, we enabled what was first a blessing for a small, knowledgeable community to be bestowed upon the rest of our peers because we could abstract not only the machine, but us as well. If we could reorganize a word into bits, and bits into bytes, then it follows from the cartesian method that we could abstract anything. As Georg Nees tells it, during the first exhibition of Computer Art (that is, graphical computed output for its own sake), a computer could indeed, draw like a human draw, if and only if one can explain to the computer how to do it. Then started the task of explaining, one after the other, all the things we needed. From mathematical operands to letters, then words, then colors.
A machine doesn't define red as being the color of blood, it defines red as being a value of 255, 0, 0, passed from the central processing unit to the graphical display device at one particular coordinate.
The more data we gave it, the longer Turing's tape had to become. We moved from magnetic ribbons to databases hosted in server farms, with entry fields in every columns, people in every row, with numbers, steadily increasing, as ornaments in the margin.



#### THE DEATH OF MIRACLES

The promise of solving the decision problem was too beautiful not to try to fulfill. At this point -at our point-, everything we can think of, everything we can effectively represent in abstract terms became computable. We could give the computer instructions -such as the best way to do this, or to do that, and then provide the "this" or the "that". We can represent a problem, and ask it for a solution, and modify the instructions until we reach a conclusion which fits the worldview of the person who wrote the program or that of the person who pays the person who wrote the program. John Conway came up with the game of life, and the 0s and 1s took on the role of living and dying. The arbitrary number of neighbors were the sole arbiters in the existence of each cell, and that toy, a the toy which decided, on its own, better and faster than any of us, who would live and who would die, that toy was taken seriously by those who did not know, or those who refused to refer to the knowledge.
The power of process started acting upon us. The end justified the means, and the political took over. Quantitative decision making overpowered the social sciences and, ultimately, the social. Data input, process and output wasn't anymore about floating point numbers, it was about the life expectancy, career paths, happiness levels and english literacy, represented on any scale. Because any scale can be normalized, be represented between 0 and 1, decided upon. Field studies were converted into charts, interviews were analyzed for frequency of utterances, emotions are transmitted through heart-rate sensors, encephalograms and other sorts of biological potentiometers. Conway's game of life paved the way for other games of life, less mathematical and more deadly. Tenure-tracks were sustained by articles published on the computer models of civil violence. Promoters and urban planners played around simulations to fix low-income housing problems. Private companies wrote instructions for the computer -a decision-making machine- to inform a judge -a decision-making human- whether another human, described through words, entered in databases, transformed into code and compiled into numbers, was more likely to commit a crime against his peers. The computer decided that some humans were more likely than others to commit crimes in the future, and we correlated these humans as low-income citizens of color.
In 1966, Joseph Weizenbaum, one of those who knew how the machine worked, that it was limited, and perhaps limiting, expressed academic interest in modeling human language. His set of instructions was a back-and-forth between machine language and human language, representing decisions made by carefully, yet vaguely worded phrases. Upon completion, he referred to it as a parody. His assistant, however, referred to it as an interlocutor. It was something to talk to, for lack of a better someone. The instructions, as it became clear to anyone, quickly showed cracks, repetitions and lack of understanding. It is possible to see it as a machine, as an elaborate system of rare earth metals with shifting motions of electrons, and yet we choose to see it as more than that.



#### THE LAST MIRACLE

> so everything can be numerized
> it seems that it is the death of miracles. all is predicted, and all is explained.
> talk about how the last miracle is renouncing data science (most paid job title in 2016)
> we develop a literacy with data
> we learn code like we learned latin, remnants of the pax romana, pax codex, something that ruled the world, and something the barbarians toppled
> the sack of rome is the erasing of the computers
> just like a painting, encoding is just representation of information
> we must learn its language, the language we came up with, to see its influences, its rhetorics and its stylistic figures.
> once we all learn to read, we can all express opinion, and maybe will come a new Luther.
